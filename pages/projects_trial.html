<div class="container-fluid">
    <div class="row" style="margin-bottom: 50px;">
        <div class="col-md-12">
            <div class="mu-service-area">
                <div class="mu-service-header">
                    <h2 class="mu-heading-title">SELECTED PROJECTS</h2>
                    <span class="mu-header-dot"></span>

                    <div class="row" style="margin-bottom: 50px;">
                    <div class="col-md-1 text-center">
                        </div>
                        <!-- First Video -->
                        <div class="col-md-4 text-center">
                            <div class="video-container">
                                <div class="embed-responsive embed-responsive-16by9">
                                    <iframe width="400" height="315" src="https://www.youtube.com/embed/3gP3euwNBjQ?si=TLcACNBdHSk2idpU" frameborder="0" allowfullscreen></iframe>
                                </div>
                                <p> 
                                    <a href="https://arxiv.org/abs/2409.16879" style="color:#479799;">
                                        GRACE: Generating Socially Appropriate Robot Actions Leveraging LLMs and Human Explanations
                                    </a>
                                    <br>
                                    <span style="display: block; font-weight: bold;">Dogan et al., IEEE ICRA (2025)</span>
                                </p>
                            </div>
                        </div>
                        
                        <div class="col-md-2 text-center">
			</div>
                        <!-- Second Video -->
                        <div class="col-md-4 text-center">
                            <div class="video-container">
                                <div class="embed-responsive embed-responsive-16by9">
                                    <iframe width="400" height="315" src="https://www.youtube.com/embed/NE7iIP2da2I?si=lThCthzW18x4rIKS" frameborder="0" allowfullscreen></iframe>
                                </div>
                                <p>
                                    <a href="https://doi.org/10.1109/HRI53351.2022.9889368" style="color:#479799;">
                                        Asking Follow-Up Clarifications to Resolve Ambiguities in Human-Robot Conversation
                                    </a>
                                    <br>
                                    <span style="display: block; font-weight: bold;">Dogan et al., ACM/IEEE HRI (2022)</span>
                                </p>
                            </div>
                        </div>


                    </div> <!-- End Row -->

                    <div class="row" style="margin-bottom: 50px;">
                        <!-- First Image -->
                        <div class="col-md-6 text-center">
                            <div class="image-container">
                                <img src="assets/images/frontiers.jpg" width="640" height="180" alt="Project Image 1" class="img-fluid">
                                <p>
                                <a href="https://doi.org/10.3389/frobt.2022.937772" style="color:#479799;">
                                        Leveraging Explainability for Understanding Object Descriptions in Ambiguous 3D Environments
                                    </a>
                                    <br>
                                    <span style="display: block; font-weight: bold;">Dogan et al., Frontiers in Robotics and AI (2023)</span>
                                </p>
                            </div>
                        </div>
                        
                        <!-- Second Image -->
                        <div class="col-md-6 text-center">
                            <div class="image-container">
                                <img src="assets/images/perspective.jpg" width="640" height="180" alt="Project Image 2" class="img-fluid">
                                <p>
                                <a href="https://doi.org/10.1016/j.robot.2020.103654" style="color:#479799;">
                                        The Impact of Adding Perspective-Taking to Spatial Referencing during Humanâ€“Robot Interaction
                                    </a>
                                    <br>
                                    <span style="display: block; font-weight: bold;">Dogan et al., Robotics and Autonomous Systems (2020)</span>
                                    </p>
                            </div>
                        </div>
                    </div> <!-- End Row -->
                                            
                    <div class="row" style="margin-bottom: 50px;">


                        <!-- Third Video -->
                        <div class="col-md-4 text-center">
                            <div class="video-container">
                                <div class="embed-responsive embed-responsive-16by9">
                                    <iframe width="400" height="315" src="https://www.youtube.com/embed/sFjBa_MHS98?si=Sr1QggC7kGzMkapc" frameborder="0" allowfullscreen></iframe>
                                </div>
                                <p>
                                    <a href="https://doi.org/10.1109/IROS40897.2019.8968510" style="color:#479799;">
                                        Learning to Generate Unambiguous Spatial Referring Expressions for Real-World Environments
                                    </a>
                                    <br>
                                    <span style="display: block; font-weight: bold;">Dogan et al., IEEE IROS (2019)</span>
                                </p>
                            </div>
                        </div>

                        <!-- Fourth Video (Random Placeholder) -->
                        <div class="col-md-4 text-center">
                            <div class="video-container">
                                <div class="embed-responsive embed-responsive-16by9">
                                    <iframe width="400" height="315" src="https://www.youtube.com/embed/U2T5meLdooo?si=oMuGW6giRMhXilVh" frameborder="0" allowfullscreen></iframe>
                                </div>
                                <p>
                                    <a href="https://doi.org/10.1109/ICRA.2018.8462925" style="color:#479799;">
                                        A Deep Incremental Boltzmann Machine for Modeling Context in Robots
                                    </a>
                                    <br>
                                    <span style="display: block; font-weight: bold;">Dogan et al., IEEE ICRA (2018)</span>
                                </p>
                            </div>
                        </div>
			<!-- Fifth Video (Random Placeholder) -->
                        <div class="col-md-4 text-center">
                            <div class="video-container">
                                <div class="embed-responsive embed-responsive-16by9">
                                    <iframe width="400" height="315" src="https://www.youtube.com/embed/J8M07ndFscY?si=Q4qfG_ZPiluEgzW9" frameborder="0" allowfullscreen></iframe>
                                </div>
                                <p>
                                    <a href="https://doi.org/10.1109/IROS.2018.8593633" style="color:#479799;">
                                       CINet: A Learning Based Approach to Incremental Context Modeling in Robots
                                    </a>
                                    <br>
                                    <span style="display: block; font-weight: bold;">Dogan et al., IEEE IROS (2018)</span>
                                </p>
                            </div>
                        </div>
                    </div> <!-- End Row -->


                </div>
            </div>
        </div>
    </div>
</div>

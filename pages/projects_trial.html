<div class="container-fluid">
    <div class="row" style="margin-bottom: 50px;">
        <div class="col-md-12">
            <div class="mu-service-area">
                <div class="mu-service-header">
                    <h2 class="mu-heading-title">SELECTED PROJECTS</h2>
                    <span class="mu-header-dot"></span>

                    <div class="row" style="margin-bottom: 50px;">
                    
                        
                    
                    
                    <div class="row" style="margin-bottom: 50px;">
			<div class="col-md-1 text-center">
                        </div>

                        <div class="col-md-3 text-center">
                            <div class="mu-about-content-center">
                                <div class="embed-responsive embed-responsive-16by9">
                                    <iframe width="400" height="315" src="https://www.youtube.com/embed/GTNCC1GkiQ4?si=jke3HijtnWcbp304" frameborder="0" allowfullscreen></iframe>
                                </div>
                                <p>
                                    <a href="https://doi.org/10.48550/arXiv.2409.16879" style="color:#479799;">
                                        GRACE: Generating Socially Appropriate Robot Actions Leveraging LLMs and Human Explanations
                                    </a>
                                    <br>
                                    <span style="display: block; font-weight: bold;">Dogan et al., IEEE ICRA (2025)</span>
                                </p>
                            </div>
                        </div>
                        
                        
                        <div class="col-md-1 text-center">
                        </div>

			
			<!-- Fifth Video (Random Placeholder) -->
                        <div class="col-md-3 text-center">
                            <div class="mu-about-content-center">
                                <div class="embed-responsive embed-responsive-16by9">
                                    <iframe width="400" height="315" src="https://www.youtube.com/embed/_P0v07Xc24Y?si=MLt-5EiVKUmp4hNQ" frameborder="0" allowfullscreen></iframe>
                                </div>
                                <p>
                                    <a href="https://doi.org/10.48550/arXiv.2409.17004" style="color:#479799;">
                                       A Model-Agnostic Approach for Semantically Driven Disambiguation in Human-Robot Interaction
                                    </a>
                                    <br>
                                    <span style="display: block; font-weight: bold;">Dogan et al., IEEE RO-MAN (under review)</span>
                                </p>
                            </div>
                        </div>
                        
                        <div class="col-md-1 text-center">
                        </div>


                        <!-- Fourth Video (Random Placeholder) -->
                        <div class="col-md-3 text-center">
                            <div class="mu-about-content-center">
                                <div class="embed-responsive embed-responsive-16by9">
                                    <iframe width="400" height="315" src="https://www.youtube.com/embed/NE7iIP2da2I?si=lThCthzW18x4rIKS" frameborder="0" allowfullscreen></iframe>
                                </div>
                                <p>
                                    <a href="https://doi.org/10.1109/HRI53351.2022.9889368" style="color:#479799;">
                                        Asking Follow-Up Clarifications to Resolve Ambiguities in Human-Robot Conversation
                                    </a>
                                    <br>
                                    <span style="display: block; font-weight: bold;">Dogan et al., ACM/IEEE HRI (2022)</span>
                                </p>
                            </div>
                        </div>
                        
                       
                    </div> <!-- End Row -->

                    <div class="row" style="margin-bottom: 50px;">
                        <!-- First Image -->
                        <div class="col-md-6 text-center">
                            <div class="mu-about-content-center">
                             	<a href="assets/images/frontiers.jpg" class="popup-link">
                                <img src="assets/images/frontiers.jpg" width="540" height="180" alt="Project Image 1" class="img-fluid">
                                </a>
                                <p>
                                <a href="https://doi.org/10.3389/frobt.2022.937772" style="color:#479799;">
                                        Leveraging Explainability for Understanding Object Descriptions in Ambiguous 3D Environments
                                    </a>
                                    <br>
                                    <span style="display: block; font-weight: bold;">Dogan et al., Frontiers in Robotics and AI (2023)</span>
                                </p>
                            </div>
                        </div>
                        
                        <!-- Second Image -->
                        <div class="col-md-6 text-center">
                            <div class="mu-about-content-center">
                            	<a href="assets/images/perspective.jpg" class="popup-link">
                                <img src="assets/images/perspective.jpg" width="620" height="180" alt="Project Image 2" class="img-fluid">
                                </a>
                                <p>
                                <a href="https://www.sciencedirect.com/science/article/pii/S0921889020304942" style="color:#479799;">
                                        The Impact of Adding Perspective-Taking to Spatial Referencing during Humanâ€“Robot Interaction
                                 </a>
                                    </a>
                                    <br>
                                    <span style="display: block; font-weight: bold;">Dogan et al., Robotics and Autonomous Systems (2020)</span>
                                    </p>
                            </div>
                        </div>
                    </div> <!-- End Row -->
                                            
                    <div class="row" style="margin-bottom: 50px;">

			<div class="col-md-1 text-center">
                        </div>

                        <!-- Third Video -->
                        <div class="col-md-3 text-center">
                            <div class="mu-about-content-center">
                                <div class="embed-responsive embed-responsive-16by9">
                                    <iframe width="400" height="315" src="https://www.youtube.com/embed/sFjBa_MHS98?si=Sr1QggC7kGzMkapc" frameborder="0" allowfullscreen></iframe>
                                </div>
                                <p>
                                    <a href="https://doi.org/10.1109/IROS40897.2019.8968510" style="color:#479799;">
                                        Learning to Generate Unambiguous Spatial Referring Expressions for Real-World Environments
                                    </a>
                                    <br>
                                    <span style="display: block; font-weight: bold;">Dogan et al., IEEE IROS (2019)</span>
                                </p>
                            </div>
                        </div>
                        
                        <div class="col-md-1 text-center">
                        </div>

                        <!-- Fourth Video (Random Placeholder) -->
                        <div class="col-md-3 text-center">
                            <div class="mu-about-content-center">
                                <div class="embed-responsive embed-responsive-16by9">
                                    <iframe width="400" height="315" src="https://www.youtube.com/embed/U2T5meLdooo?si=oMuGW6giRMhXilVh" frameborder="0" allowfullscreen></iframe>
                                </div>
                                <p>
                                    <a href="https://doi.org/10.1109/ICRA.2018.8462925" style="color:#479799;">
                                        A Deep Incremental Boltzmann Machine for Modeling Context in Robots
                                    </a>
                                    <br>
                                    <span style="display: block; font-weight: bold;">Dogan et al., IEEE ICRA (2018)</span>
                                </p>
                            </div>
                        </div>
                        
                        <div class="col-md-1 text-center">
                        </div>
                        
                        
			<!-- Fifth Video (Random Placeholder) -->
                        <div class="col-md-3 text-center">
                            <div class="mu-about-content-center">
                                <div class="embed-responsive embed-responsive-16by9">
                                    <iframe width="400" height="315" src="https://www.youtube.com/embed/J8M07ndFscY?si=Q4qfG_ZPiluEgzW9" frameborder="0" allowfullscreen></iframe>
                                </div>
                                <p>
                                    <a href="https://doi.org/10.1109/IROS.2018.8593633" style="color:#479799;">
                                       CINet: A Learning Based Approach to Incremental Context Modeling in Robots
                                    </a>
                                    <br>
                                    <span style="display: block; font-weight: bold;">Dogan et al., IEEE IROS (2018)</span>
                                </p>
                            </div>
                        </div>
                    </div> <!-- End Row -->


                </div>
            </div>
        </div>
    </div>
</div>
